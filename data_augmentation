#-----------------------for google colab
! pip install kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets download jakeshbohaju/brain-tumor
! unzip brain-tumor.zip

#------------------------importation
import pandas as pd
import numpy as np
import os
import tensorflow as tf
import datetime
import cv2
import seaborn as sb
from tensorflow import keras
from tensorflow.keras import layers, Input
from keras.layers import InputLayer, MaxPooling2D, Flatten, Dense, Conv2D, Dropout
from keras.losses import BinaryCrossentropy
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50
from tensorflow.keras.optimizers import Adam, SGD
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from PIL.Image import open
from  matplotlib import pyplot as plt
import matplotlib.image as mpimg
import random
%matplotlib inline
from tensorflow.python.ops.numpy_ops import np_config
from sklearn.metrics import confusion_matrix
from keras.callbacks import ModelCheckpoint, EarlyStopping
#---------------------------- Constants
IMAGE_DATASET = "/content/Brain Tumor/Brain Tumor"
IMG_HEIGHT = 224
IMG_WIDTH = 224
EPOCHS = 50 
#------------------------ We will import the csv file containing the features and the classes of the images
cortex_df = pd.read_csv("/content/Brain Tumor.csv") #Lire un fichier de valeurs séparées par des virgules (csv) dans matrice
#cortex_df.head()
#Cette fonction renvoie les n premières lignes de l'objet en fonction de la position.
#Il est utile pour tester rapidement si votre objet contient le bon type de données.
#--------------------------
dataset_df = pd.DataFrame()#A Data frame is a two-dimensional data structure
dataset_df["Image"] = cortex_df["Image"]#on crée une nouvelle dataframe avec colonne image
dataset_df["Class"] = cortex_df["Class"]#et une colonne avec label
path_list = [] #on crée une liste vide pour mettre les path d'accès aux images
for img_path in os.listdir(IMAGE_DATASET): #on va lister toutes les images dans le dataset
    path_list.append( os.path.join(IMAGE_DATASET,img_path))#on rajoute dans la liste vide les paths de toutes les images
path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in path_list}  #This method returns a tuple that represents root and ext part of the specified path name.
#Return the base name of pathname path. This is the second element of the pair returned by passing path to the function
dataset_df["paths"] = cortex_df["Image"].map(path_dict.get)
dataset_df["pixels"] = dataset_df["paths"].map(lambda x:np.asarray(open(x).resize((IMG_HEIGHT,IMG_WIDTH))))
dataset_df.head()

#-----------------------------
#I will try to augment my database
img = dataset_df["pixels"][20]
plt.figure(figsize=(10,10))
ax=plt.subplot(1,2,1)
plt.title('Original image')
plt.imshow(img)
ax=plt.subplot(1,2,2)
plt.title('Augmented image')
flipped = tf.image.flip_left_right(img)
plt.imshow(flipped)
#---------------------------
np_config.enable_numpy_behavior()
image_list2 = [] #on crée une liste d'image
for i in range(len(dataset_df)):
  brain_image = dataset_df["pixels"][i].astype(np.float32)#on ajoute les images en float une par une
  brain_image /= 255
  image_list2.append(brain_image)
  flipped = tf.image.flip_left_right(dataset_df["pixels"][i])
  brain_image_flipped = flipped.astype(np.float32)#on ajoute les images en float une par une
  brain_image_flipped /= 255
  image_list2.append(brain_image_flipped)
X = np.array(image_list2)
print(X.shape)
#---------------------------------
#I verify the augmentation
img = X[20]
plt.figure(figsize=(10,10))
ax=plt.subplot(1,2,1)
plt.title('Original image')
plt.imshow(img)
ax=plt.subplot(1,2,2)
plt.title('Augmented image')
img = X[21]
plt.imshow(img)
#--------------------------------
label_list = [] #on crée une liste d'image
for i in range(len(dataset_df)):
  label = dataset_df["Class"][i]#on ajoute les images en float une par une
  label_list.append(label)
  label_list.append(label)
y = np.array(label_list)
y.shape
#----------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
print('The shape of the X_train :'+' '+str(X_train.shape)) #images pour entrainements
print('The size of the X_train :'+' '+str(X_train.shape[0]))#labels pour entrainement
print('The shape of the X_test :'+' '+str(X_test.shape))#images pour test
print('The size of the X_test:'+' '+str(X_test.shape[0]))#labels pour test
